{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "softwareDefectPrediction.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ixCXQh1TcCd5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "babe72ca-a835-4840-aa2c-995cb46b8b8f"
      },
      "source": [
        "''' \n",
        "Accessing google drive to get dataset and unzip\n",
        "'''\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "\n",
        "!cp 'drive/My Drive/preprocessing/featuress.csv' /content\n",
        "\n",
        "!cp 'drive/My Drive/preprocessing/labelss.csv' /content"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BiKgFxR0vGNi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "975f6533-fdca-42a4-f3a6-0e9c6231efd4"
      },
      "source": [
        "import pandas as pd\n",
        "from pandas import DataFrame\n",
        "import cv2\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Activation, Dropout, Flatten, Conv2D, MaxPool2D, MaxPooling2D, Embedding, LSTM, Conv1D, MaxPool1D, GRU\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras.optimizers import SGD, RMSprop, Adam\n",
        "from numpy import savetxt\n",
        "import sklearn as sk\n",
        "from keras import backend as K\n",
        "\n",
        "files = pd.read_csv(\"featuress.csv\").iloc[ 0:10019, 0:1200]\n",
        "labels = pd.read_csv(\"labelss.csv\").iloc[ : , 1]\n",
        "\n",
        "RNN = pd.read_csv(\"featuress.csv\").iloc[ 0:10019, 0:500]\n",
        "RNNS = pd.read_csv(\"labelss.csv\").iloc[ 0:10019 , 1]\n",
        "RNN = sk.preprocessing.scale(RNN)\n",
        "RNN = np.array(RNN)\n",
        "RNN = RNN.astype('float32')\n",
        "RNN_TrainFiles, RNN_TestFiles, RNN_TrainLabels , RNN_testLabels = train_test_split(RNN , RNNS, test_size=0.3)\n",
        "\n",
        "files = sk.preprocessing.scale(files)\n",
        "\n",
        "files = np.array(files)\n",
        "labels = np.array(labels)\n",
        "files = files.astype('float32')\n",
        "\n",
        "\n",
        "'''\n",
        "    Dividing the data into train/test split\n",
        "'''\n",
        "\n",
        "train_Files, test_Files, train_labels , test_labels = train_test_split(files , labels, test_size=0.3)\n",
        "#RNN_TrainFiles = train_Files\n",
        "#RNN_TestFiles = test_Files\n",
        "#RNN_TrainLabels = train_labels\n",
        "#RNN_testLabels = test_labels\n",
        "\n",
        "print(\"Train shape\" , train_Files.shape)\n",
        "print(\"labels Shape\", train_labels.shape)\n",
        "\n",
        "train_Files = train_Files.reshape((7013,1200,1,1))\n",
        "test_Files = test_Files.reshape((3006,1200,1,1))\n",
        "\n",
        "train_Files2 = train_Files.reshape((7013,1200,1))\n",
        "test_Files2 = test_Files.reshape((3006,1200,1))\n",
        "\n",
        "RNN_TrainFiles = RNN_TrainFiles.reshape((7013,500,1)) #1200\n",
        "RNN_TestFiles = RNN_TestFiles.reshape((3006,500,1)) #1200\n",
        "\n",
        "train_labels = np.asarray(train_labels).astype('float32').reshape((-1,1))\n",
        "test_labels = np.asarray(test_labels).astype('float32').reshape((-1,1))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train shape (7013, 1200)\n",
            "labels Shape (7013,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y2ZKMvbeITo5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def recall_m(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "    recall = true_positives / (possible_positives + K.epsilon())\n",
        "    return recall\n",
        "\n",
        "def precision_m(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "    precision = true_positives / (predicted_positives + K.epsilon())\n",
        "    return precision\n",
        "\n",
        "def f1_m(y_true, y_pred):\n",
        "    precision = precision_m(y_true, y_pred)\n",
        "    recall = recall_m(y_true, y_pred)\n",
        "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def softwareDefectCNN1D(): \n",
        "   \n",
        "\n",
        "  '''\n",
        "      CNN model with 1D convolutional layers\n",
        "  '''\n",
        "\n",
        "  classifier = Sequential()\n",
        "  \n",
        "\n",
        "  classifier.add(Conv1D(96, 1, input_shape=(1200,1), activation='relu'))\n",
        "  classifier.add(MaxPool1D(pool_size= 1, strides=2))\n",
        "  #classifier.add(BatchNormalization())\n",
        "\n",
        "  classifier.add(Conv1D(256, 1, activation='relu'))\n",
        "  classifier.add(MaxPool1D(pool_size= 1, strides=2))\n",
        " # classifier.add(BatchNormalization())\n",
        "\n",
        "  classifier.add(Conv1D(384, 1, activation='relu'))\n",
        "  classifier.add(MaxPool1D(pool_size= 1, strides=2))\n",
        "  #classifier.add(BatchNormalization())\n",
        "\n",
        "  #classifier.add(Conv2D(384, 1, activation='relu'))\n",
        "  #classifier.add(MaxPooling2D(pool_size=(1, 1), strides=2))\n",
        "  #classifier.add(BatchNormalization())\n",
        "\n",
        "  classifier.add(Conv1D(256, 1, activation='relu'))\n",
        "\n",
        "  classifier.add(Flatten())\n",
        "\n",
        "  classifier.add(Dense(1024, activation='relu'))\n",
        "  classifier.add(Dropout(0.6))\n",
        "\n",
        "  classifier.add(Dense(512, activation='relu'))\n",
        "  classifier.add(Dropout(0.6))\n",
        "  \n",
        "\n",
        "  classifier.add(Dense(64, activation='relu'))\n",
        "  classifier.add(Dropout(0.6))\n",
        "\n",
        "  classifier.add(Dense(64, activation='relu'))\n",
        "  classifier.add(Dropout(0.6))\n",
        "\n",
        "  classifier.add(Dense(16, activation='relu'))\n",
        "  classifier.add(Dropout(0.6))\n",
        "\n",
        "  classifier.add(Dense(1, activation='sigmoid'))\n",
        "  \n",
        "  return classifier\n",
        "\n",
        "\n",
        "\n",
        "  '''\n",
        "    Compilation and training of the model with \n",
        "    Epochs: 100\n",
        "    Optimizer: Adam\n",
        "    learning rate: 0.0001\n",
        "    batch size: 16\n",
        "    loss function: binary crossentropy\n",
        "    Accuracy: 88%\n",
        "'''\n",
        " \n",
        "\n",
        "softwareDefectCNN1D = softwareDefectCNN1D()\n",
        "softwareDefectCNN1D.compile(loss='binary_crossentropy', optimizer=Adam(lr=0.0001), metrics=[\"accuracy\",f1_m])\n",
        "hist = softwareDefectCNN1D.fit(train_Files2, train_labels, batch_size=16, epochs=100, verbose=1 ,validation_data=(test_Files2,test_labels), shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sAeFbyk9j_Jj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "CNN_Predict = softwareDefectCNN1D.predict(test_Files)\n",
        "rounded = [round(x[0]) for x in CNN_Predict]\n",
        "conf_matrix = confusion_matrix(test_labels,rounded)\n",
        "print(\"Confustion matrix: \")\n",
        "print(conf_matrix)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VkMUBZVPL-JU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def recall_m(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "    recall = true_positives / (possible_positives + K.epsilon())\n",
        "    return recall\n",
        "\n",
        "def precision_m(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "    precision = true_positives / (predicted_positives + K.epsilon())\n",
        "    return precision\n",
        "\n",
        "def f1_m(y_true, y_pred):\n",
        "    precision = precision_m(y_true, y_pred)\n",
        "    recall = recall_m(y_true, y_pred)\n",
        "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n",
        "\n",
        "def softwareDefectRNN():\n",
        "\n",
        "\n",
        "  classifier = Sequential()\n",
        "#512\n",
        "  classifier.add(LSTM(512,input_shape=(500,1), recurrent_activation='sigmoid', recurrent_dropout=0, unroll=False, use_bias=True, return_sequences=True))# recurrent_activation='sigmoid', recurrent_dropout=0, unroll=False, use_bias=True, return_sequences=True\n",
        "\n",
        "  #classifier.add(LSTM(512, recurrent_activation='sigmoid', recurrent_dropout=0, unroll=False, use_bias=True))\n",
        "\n",
        "  classifier.add(Flatten())\n",
        "\n",
        "  #classifier.add(Dense(128, activation='softplus'))\n",
        "\n",
        "  #classifier.add(Dense(64, activation='relu'))\n",
        "\n",
        "  #classifier.add(Dense(32, activation='sigmoid'))\n",
        "  \n",
        "  #classifier.add(Dense(16, activation='sigmoid'))\n",
        "\n",
        "  classifier.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "  return classifier\n",
        "\n",
        "\n",
        "softwareDefectRNN = softwareDefectRNN()\n",
        "softwareDefectRNN.compile(loss='binary_crossentropy', optimizer=Adam(lr=0.00001), metrics=[\"accuracy\"])\n",
        "hist =softwareDefectRNN.fit(RNN_TrainFiles, RNN_TrainLabels, batch_size=4, epochs=15, verbose=1 ,validation_data=(RNN_TestFiles,RNN_testLabels), shuffle=True) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sbUBSLsKDGxX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "521b1ec8-4675-4fa5-cd59-7f89f9194e3c"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "RNN_Predict = softwareDefectRNN.predict(RNN_TestFiles)\n",
        "rounded = [round(x[0]) for x in RNN_Predict]\n",
        "conf_matrix = confusion_matrix(test_labels,rounded)\n",
        "print(\"Confustion matrix: \")\n",
        "print(conf_matrix)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confustion matrix: \n",
            "[[1715  306]\n",
            " [ 828  157]]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}